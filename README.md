# ğŸ§  ChurnInsight â€” Modelo de Machine Learning

> Modelo de Machine Learning responsÃ¡vel por prever **churn de clientes**, utilizado como parte central do ecossistema **ChurnInsight**.

Este repositÃ³rio contÃ©m todo o pipeline de **prÃ©-processamento, treinamento, avaliaÃ§Ã£o e serializaÃ§Ã£o** do modelo de ML que Ã© consumido pela API backend do projeto.

---

## ğŸš€ VisÃ£o Geral

O **ChurnInsight Model** Ã© responsÃ¡vel por analisar dados de clientes e gerar uma **probabilidade de churn**, permitindo que sistemas de negÃ³cio tomem decisÃµes baseadas em dados.

Ele faz parte de uma soluÃ§Ã£o maior composta por:

| Componente      | RepositÃ³rio                                                                                                      |
| --------------- | ---------------------------------------------------------------------------------------------------------------- |
| ğŸ–¥ï¸ Frontend    | [https://github.com/isaacmnss/churnInsight-frontend](https://github.com/isaacmnss/churnInsight-frontend)         |
| âš™ï¸ API Backend  | [https://github.com/isaacmnss/churnInsight](https://github.com/isaacmnss/churnInsight) |
| ğŸ§  Modelo de ML | [https://github.com/isaacmnss/churnInsight-model](https://github.com/isaacmnss/churnInsight-model)               |

---

## ğŸ¯ Objetivo do Modelo

O modelo tem como objetivo:

* Prever a chance de **evasÃ£o (churn)** de clientes
* Ajudar empresas a **antecipar perdas**
* Servir previsÃµes para consumo via API REST

O output do modelo normalmente Ã©:

* **Classe** (churn / nÃ£o churn)
* **Probabilidade associada** Ã  previsÃ£o

---

## ğŸ§ª Dataset

O modelo foi treinado utilizando o **Bank Customer Churn Dataset**, disponÃ­vel publicamente no Kaggle:

ğŸ”— [https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn](https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn)

O dataset contÃ©m informaÃ§Ãµes de clientes bancÃ¡rios com atributos demogrÃ¡ficos, financeiros e comportamentais, como:

* Idade
* Score de crÃ©dito
* Saldo em conta
* NÃºmero de produtos
* Atividade do cliente

> âš ï¸ O dataset Ã© utilizado **exclusivamente para fins educacionais e de demonstraÃ§Ã£o**. Os dados nÃ£o representam clientes reais.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.10+**
* **Pandas**
* **NumPy**
* **Scikit-learn**
* **Matplotlib / Seaborn** (anÃ¡lise exploratÃ³ria)
* **Joblib / Pickle** (serializaÃ§Ã£o do modelo)

---

## ğŸ§© Pipeline do Modelo

O fluxo geral do modelo segue as etapas abaixo:

1. **Carregamento dos dados**
2. **Limpeza e prÃ©-processamento**

   * Tratamento de valores nulos
   * Encoding de variÃ¡veis categÃ³ricas
   * NormalizaÃ§Ã£o/Escala
3. **Treinamento do modelo**
4. **AvaliaÃ§Ã£o (accuracy, precision, recall, etc.)**
5. **SerializaÃ§Ã£o do modelo treinado**
6. **IntegraÃ§Ã£o com a API Backend**

---

## ğŸš€ Como Executar Localmente

### 1ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone https://github.com/isaacmnss/churnInsight-model.git
cd churnInsight-model
```

### 2ï¸âƒ£ Criar ambiente virtual (opcional, recomendado)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate     # Windows
```

### 3ï¸âƒ£ Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Executar o treinamento

```bash
python train.py
```

> Indicativo: ajuste o nome do script conforme a estrutura real do projeto.

---

## ğŸ“¦ Artefatos Gerados

ApÃ³s o treinamento, sÃ£o gerados arquivos como:

* ğŸ“ Modelo treinado (`.pkl` ou `.joblib`)
* ğŸ“Š MÃ©tricas de avaliaÃ§Ã£o
* ğŸ“ˆ GrÃ¡ficos de desempenho

Esses artefatos sÃ£o consumidos diretamente pela **API Backend**.

---

## ğŸ”Œ IntegraÃ§Ã£o com a API

A API Backend carrega o modelo treinado para:

* Receber dados de entrada via HTTP
* Executar a prediÃ§Ã£o
* Retornar o resultado ao frontend

ğŸ“Œ RepositÃ³rio da API:

```
https://github.com/isaacmnss/churnInsight
```

---

## ğŸ§ª Testes e AvaliaÃ§Ã£o

O modelo pode ser avaliado utilizando mÃ©tricas como:

* Accuracy
* Precision
* Recall
* F1-score
* ROC-AUC

Essas mÃ©tricas ajudam a validar a qualidade das previsÃµes.

---

## â¤ï¸ Agradecimentos

Projeto desenvolvido no contexto de um **Hackathon** promovido por Alura e Oracle durante o bootcamp Oracle Next Education

Agradecimentos especiais ao restante dos membros da equipe:

### Data Scientists

- Pedro Camargo

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/pedrocamargo1/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/Pdrnho)

- Suellen Costa


[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/suellensilva86)

- Antonio Sergio

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/asccjr/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/ASCCJR)

### Devs Backend

- Paulo Cruz

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/paulo-cruz-dev/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/PauloBrazilian)

- Isaaac Meneses

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/isaac-me