# üß† ChurnInsight ‚Äî Modelo de Machine Learning

> Modelo de Machine Learning respons√°vel por prever **churn de clientes**, utilizado como parte central do ecossistema **ChurnInsight**.

Este reposit√≥rio cont√©m todo o pipeline de **pr√©-processamento, treinamento, avalia√ß√£o e serializa√ß√£o** do modelo de ML que √© consumido pela API backend do projeto.

---

## üöÄ Vis√£o Geral

O **ChurnInsight Model** √© respons√°vel por analisar dados de clientes e gerar uma **probabilidade de churn**, permitindo que sistemas de neg√≥cio tomem decis√µes baseadas em dados.

Ele faz parte de uma solu√ß√£o maior composta por:

| Componente      | Reposit√≥rio                                                                                                      |
| --------------- | ---------------------------------------------------------------------------------------------------------------- |
| üñ•Ô∏è Frontend    | [https://github.com/isaacmnss/churnInsight-frontend](https://github.com/isaacmnss/churnInsight-frontend)         |
| ‚öôÔ∏è API Backend  | [https://github.com/isaacmnss/churnInsight](https://github.com/isaacmnss/churnInsight) |
| üß† Modelo de ML | [https://github.com/isaacmnss/churnInsight-model](https://github.com/isaacmnss/churnInsight-model)               |

---

## üéØ Objetivo do Modelo

O modelo tem como objetivo:

* Prever a chance de **evas√£o (churn)** de clientes
* Ajudar empresas a **antecipar perdas**
* Servir previs√µes para consumo via API REST

O output do modelo normalmente √©:

* **Classe** (churn / n√£o churn)
* **Probabilidade associada** √† previs√£o

---

## üß™ Dataset

O modelo foi treinado utilizando o **Bank Customer Churn Dataset**, dispon√≠vel publicamente no Kaggle:

üîó [https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn](https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn)

O dataset cont√©m informa√ß√µes de clientes banc√°rios com atributos demogr√°ficos, financeiros e comportamentais, como:

* Idade
* Score de cr√©dito
* Saldo em conta
* N√∫mero de produtos
* Atividade do cliente

> ‚ö†Ô∏è O dataset √© utilizado **exclusivamente para fins educacionais e de demonstra√ß√£o**. Os dados n√£o representam clientes reais.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Python 3.10+**
* **Pandas**
* **NumPy**
* **Scikit-learn**
* **Matplotlib / Seaborn** (an√°lise explorat√≥ria)
* **Joblib / Pickle** (serializa√ß√£o do modelo)

---

## üß© Pipeline do Modelo

O fluxo geral do modelo segue as etapas abaixo:

1. **Carregamento dos dados**
2. **Limpeza e pr√©-processamento**

   * Tratamento de valores nulos
   * Encoding de vari√°veis categ√≥ricas
   * Normaliza√ß√£o/Escala
3. **Treinamento do modelo**
4. **Avalia√ß√£o (accuracy, precision, recall, etc.)**
5. **Serializa√ß√£o do modelo treinado**
6. **Integra√ß√£o com a API Backend**

---

## üöÄ Como Executar Localmente

### 1Ô∏è‚É£ Clonar o reposit√≥rio

```bash
git clone https://github.com/isaacmnss/churnInsight-model.git
cd churnInsight-model
```

### 2Ô∏è‚É£ Criar ambiente virtual (opcional, recomendado)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate     # Windows
```

### 3Ô∏è‚É£ Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

### 4Ô∏è‚É£ Executar o treinamento

```bash
python train.py
```

> Indicativo: ajuste o nome do script conforme a estrutura real do projeto.

---

## üì¶ Artefatos Gerados

Ap√≥s o treinamento, s√£o gerados arquivos como:

* üìÅ Modelo treinado (`.pkl` ou `.joblib`)
* üìä M√©tricas de avalia√ß√£o
* üìà Gr√°ficos de desempenho

Esses artefatos s√£o consumidos diretamente pela **API Backend**.

---

## üîå Integra√ß√£o com a API

A API Backend carrega o modelo treinado para:

* Receber dados de entrada via HTTP
* Executar a predi√ß√£o
* Retornar o resultado ao frontend

üìå Reposit√≥rio da API:

```
https://github.com/isaacmnss/churnInsight
```

---

## üß™ Testes e Avalia√ß√£o

O modelo pode ser avaliado utilizando m√©tricas como:

* Accuracy
* Precision
* Recall
* F1-score
* ROC-AUC

Essas m√©tricas ajudam a validar a qualidade das previs√µes.

---

## ‚ù§Ô∏è Agradecimentos

Projeto desenvolvido no contexto de um **Hackathon** promovido por Alura e Oracle durante o bootcamp Oracle Next Education

Agradecimentos especiais ao restante dos membros da equipe:

### Data Scientists

- Pedro Camargo

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/pedrocamargo1/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/Pdrnho)

- Suellen Costa


[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/suellensilva86)

- Antonio Sergio

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/asccjr/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/ASCCJR)

### Devs Backend

- Paulo Cruz

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/paulo-cruz-dev/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/PauloBrazilian)

- Isaaac Meneses

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/isaac-meneses/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/isaacmnss)
